{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_3correction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-Qe3ygLV44_B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "b5eb3ede-f491-4efb-f7ad-6c15ed31cd16"
      },
      "source": [
        " from sklearn.feature_extraction.text import CountVectorizer\n",
        " from nltk.corpus import stopwords\n",
        " import pandas as pd\n",
        " import string\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "  "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7CKmsoeypkMM",
        "colab": {}
      },
      "source": [
        "text = open(r\"corona1.txt\", encoding=\"utf-8\").read()\n",
        "lower_case = text.lower()\n",
        "cleaned_text = [lower_case.translate(str.maketrans('', '', string.punctuation))]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGjiJFIIhISK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = stopwords.words()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SLU_heOkqLC7",
        "colab": {}
      },
      "source": [
        "vect1=CountVectorizer(stop_words=stop_words)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Oercy5D3qOHq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "313981e2-4dcd-4e33-efed-1daff6b7a1b2"
      },
      "source": [
        "vect1.fit_transform(cleaned_text)\n",
        "print(\"bag of words:\",vect1.get_feature_names())#"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bag of words: ['accept', 'accepting', 'according', 'across', 'add', 'adding', 'adds', 'argues', 'argument', 'around', 'blamed', 'call', 'cant', 'caption', 'community', 'continued', 'copyrightgetty', 'could', 'countries', 'country', 'data', 'debate', 'definition', 'denials', 'densely', 'deny', 'didnt', 'dr', 'early', 'epidemiologist', 'everybody', 'existence', 'experts', 'failure', 'forthright', 'government', 'guess', 'happen', 'happened', 'hasnt', 'highly', 'image', 'images', 'improving', 'india', 'infectious', 'itwe', 'jameel', 'kant', 'keep', 'kumar', 'lalit', 'leading', 'like', 'localised', 'mandatory', 'many', 'matter', 'much', 'needs', 'nowso', 'obvious', 'official', 'often', 'overnight', 'pandemic', 'places', 'pointless', 'policies', 'populated', 'possibility', 'pressure', 'proves', 'rather', 'reason', 'released', 'reluctant', 'said', 'say', 'says', 'scanning', 'science', 'see', 'sees', 'several', 'since', 'spark', 'spread', 'stages', 'stance', 'strategy', 'support', 'term', 'thermal', 'topic', 'transmission', 'unnecessary', 'virus', 'weeks', 'whether', 'worked']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8dyBbOVfp205",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fa82c934-b2b4-4245-9ac0-89bf6f9a0fb7"
      },
      "source": [
        "vect1.vocabulary_"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accept': 0,\n",
              " 'accepting': 1,\n",
              " 'according': 2,\n",
              " 'across': 3,\n",
              " 'add': 4,\n",
              " 'adding': 5,\n",
              " 'adds': 6,\n",
              " 'argues': 7,\n",
              " 'argument': 8,\n",
              " 'around': 9,\n",
              " 'blamed': 10,\n",
              " 'call': 11,\n",
              " 'cant': 12,\n",
              " 'caption': 13,\n",
              " 'community': 14,\n",
              " 'continued': 15,\n",
              " 'copyrightgetty': 16,\n",
              " 'could': 17,\n",
              " 'countries': 18,\n",
              " 'country': 19,\n",
              " 'data': 20,\n",
              " 'debate': 21,\n",
              " 'definition': 22,\n",
              " 'denials': 23,\n",
              " 'densely': 24,\n",
              " 'deny': 25,\n",
              " 'didnt': 26,\n",
              " 'dr': 27,\n",
              " 'early': 28,\n",
              " 'epidemiologist': 29,\n",
              " 'everybody': 30,\n",
              " 'existence': 31,\n",
              " 'experts': 32,\n",
              " 'failure': 33,\n",
              " 'forthright': 34,\n",
              " 'government': 35,\n",
              " 'guess': 36,\n",
              " 'happen': 37,\n",
              " 'happened': 38,\n",
              " 'hasnt': 39,\n",
              " 'highly': 40,\n",
              " 'image': 41,\n",
              " 'images': 42,\n",
              " 'improving': 43,\n",
              " 'india': 44,\n",
              " 'infectious': 45,\n",
              " 'itwe': 46,\n",
              " 'jameel': 47,\n",
              " 'kant': 48,\n",
              " 'keep': 49,\n",
              " 'kumar': 50,\n",
              " 'lalit': 51,\n",
              " 'leading': 52,\n",
              " 'like': 53,\n",
              " 'localised': 54,\n",
              " 'mandatory': 55,\n",
              " 'many': 56,\n",
              " 'matter': 57,\n",
              " 'much': 58,\n",
              " 'needs': 59,\n",
              " 'nowso': 60,\n",
              " 'obvious': 61,\n",
              " 'official': 62,\n",
              " 'often': 63,\n",
              " 'overnight': 64,\n",
              " 'pandemic': 65,\n",
              " 'places': 66,\n",
              " 'pointless': 67,\n",
              " 'policies': 68,\n",
              " 'populated': 69,\n",
              " 'possibility': 70,\n",
              " 'pressure': 71,\n",
              " 'proves': 72,\n",
              " 'rather': 73,\n",
              " 'reason': 74,\n",
              " 'released': 75,\n",
              " 'reluctant': 76,\n",
              " 'said': 77,\n",
              " 'say': 78,\n",
              " 'says': 79,\n",
              " 'scanning': 80,\n",
              " 'science': 81,\n",
              " 'see': 82,\n",
              " 'sees': 83,\n",
              " 'several': 84,\n",
              " 'since': 85,\n",
              " 'spark': 86,\n",
              " 'spread': 87,\n",
              " 'stages': 88,\n",
              " 'stance': 89,\n",
              " 'strategy': 90,\n",
              " 'support': 91,\n",
              " 'term': 92,\n",
              " 'thermal': 93,\n",
              " 'topic': 94,\n",
              " 'transmission': 95,\n",
              " 'unnecessary': 96,\n",
              " 'virus': 97,\n",
              " 'weeks': 98,\n",
              " 'whether': 99,\n",
              " 'worked': 100}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O9JdX-EKsyYW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e82bb6fa-a829-4f92-8517-642fb6d63588"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bDzV4BPxqke2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "19b24052-450e-4e06-dfd6-95a6fdcd3a1b"
      },
      "source": [
        "c_vect=CountVectorizer(stop_words=stop_words)\n",
        "c_vect.fit(cleaned_text)#"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                ngram_range=(1, 1), preprocessor=None,\n",
              "                stop_words=['إذ', 'إذا', 'إذما', 'إذن', 'أف', 'أقل', 'أكثر',\n",
              "                            'ألا', 'إلا', 'التي', 'الذي', 'الذين', 'اللاتي',\n",
              "                            'اللائي', 'اللتان', 'اللتيا', 'اللتين', 'اللذان',\n",
              "                            'اللذين', 'اللواتي', 'إلى', 'إليك', 'إليكم',\n",
              "                            'إليكما', 'إليكن', 'أم', 'أما', 'أما', 'إما', 'أن', ...],\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1z3y4sB4q-0q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "83194e04-dc9f-4e30-fed0-8b820810bf0c"
      },
      "source": [
        "\n",
        "\n",
        "text = open('virus.txt', encoding=\"utf-8\").read()\n",
        "lower_case = text.lower()\n",
        "cleaned_text = [lower_case.translate(str.maketrans('', '', string.punctuation))]\n",
        "c_new_vect=c_vect.transform(cleaned_text)\n",
        "print(\"Text Present at\",c_new_vect.toarray())\n",
        "print(\"original indaxes\",vect1.get_feature_names())#"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text Present at [[2 0 1 0 0 0 1 0 0 0 0 0 1 1 4 0 1 0 0 1 0 0 1 0 0 0 0 2 0 0 0 0 0 0 0 2\n",
            "  0 0 0 0 0 2 1 0 2 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 1 2 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 5 0 1 0 0 0]]\n",
            "original indaxes ['accept', 'accepting', 'according', 'across', 'add', 'adding', 'adds', 'argues', 'argument', 'around', 'blamed', 'call', 'cant', 'caption', 'community', 'continued', 'copyrightgetty', 'could', 'countries', 'country', 'data', 'debate', 'definition', 'denials', 'densely', 'deny', 'didnt', 'dr', 'early', 'epidemiologist', 'everybody', 'existence', 'experts', 'failure', 'forthright', 'government', 'guess', 'happen', 'happened', 'hasnt', 'highly', 'image', 'images', 'improving', 'india', 'infectious', 'itwe', 'jameel', 'kant', 'keep', 'kumar', 'lalit', 'leading', 'like', 'localised', 'mandatory', 'many', 'matter', 'much', 'needs', 'nowso', 'obvious', 'official', 'often', 'overnight', 'pandemic', 'places', 'pointless', 'policies', 'populated', 'possibility', 'pressure', 'proves', 'rather', 'reason', 'released', 'reluctant', 'said', 'say', 'says', 'scanning', 'science', 'see', 'sees', 'several', 'since', 'spark', 'spread', 'stages', 'stance', 'strategy', 'support', 'term', 'thermal', 'topic', 'transmission', 'unnecessary', 'virus', 'weeks', 'whether', 'worked']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RB82uXU6sE-B",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}